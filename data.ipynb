{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e166c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac0627b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_dir = os.getcwd()\n",
    "work_dir = os.path.dirname(this_dir)\n",
    "data_dir = os.path.join(work_dir, 'data')\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e53012",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### setting area #####\n",
    "\n",
    "consonant = 'c' \n",
    "\n",
    "# mean values of the consonant\n",
    "\n",
    "cog = 7000\n",
    "\n",
    "fri_dur = 174\n",
    "\n",
    "# means of cog and frication duration\n",
    "\n",
    "'''\n",
    "ts: 4000, 96\n",
    "tc: 7000, 96\n",
    "s: 4000, 174\n",
    "c: 7000, 174\n",
    "\n",
    "Transcription for file names:\n",
    "\n",
    "tʂ: ts\n",
    "tɕ: tc\n",
    "ʂ: s\n",
    "ɕ: c\n",
    "\n",
    "'''\n",
    "\n",
    "vowel = 'i'\n",
    "\n",
    "# formants\n",
    "f_vals = [3372, 2761, 437] # f3, f2, f1\n",
    "\n",
    "'''\n",
    "i: 3372, 2761, 437\n",
    "ɪ: 3053, 2365, 483\n",
    "e: 3047, 2530, 536\n",
    "ɛ: 2979, 2058, 731\n",
    "u: 2735, 1105, 459\n",
    "ʊ: 2827, 1225, 519\n",
    "o: 2828, 1035, 555\n",
    "ɔ: 2824, 1136, 781\n",
    "\n",
    "Transcription for file names:\n",
    "\n",
    "i: i *\n",
    "ɪ: L\n",
    "e: e *\n",
    "ɛ: F\n",
    "u: u *\n",
    "ʊ: W\n",
    "o: o *\n",
    "ɔ: D\n",
    "\n",
    "*: used in training\n",
    "\n",
    "'''\n",
    "\n",
    "word = vowel + consonant + vowel\n",
    "\n",
    "# no. of tokens for each word\n",
    "sample_size = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d98281c",
   "metadata": {},
   "source": [
    "### Consonant synthesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6a9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd36b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_f_means = np.array([cog, fri_dur])\n",
    "c_f_stds = np.array([500, 13])\n",
    "\n",
    "con_means = np.array([200, 0.5, 1, 50, 60]) # sta_dev, skewness, kurtosis, bur_int, fri_int\n",
    "con_stds = con_means * 0.05\n",
    "\n",
    "con_means = np.concatenate((c_f_means, con_means))\n",
    "con_stds = np.concatenate((c_f_stds, con_stds))\n",
    "\n",
    "consonants = np.zeros((sample_size, len(con_means)))\n",
    "for i in range(len(con_means)):\n",
    "    a, b = (con_means[i] - 2*con_stds[i] - con_means[i]) / con_stds[i], (con_means[i] + 2*con_stds[i] - con_means[i]) / con_stds[i]\n",
    "    dist = truncnorm(a, b, loc = con_means[i], scale = con_stds[i])\n",
    "    consonants[:, i] = dist.rvs(size = sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7ed1be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.10909227e+03 1.63178269e+02 2.05436293e+02 5.14848799e-01\n",
      " 9.08360303e-01 4.77657712e+01 6.48044470e+01 2.00000000e+02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# total duration of fixed value 200 for consonants\n",
    "con_dur = np.full((sample_size, 1), 200)\n",
    "\n",
    "# zero values for all other features\n",
    "zeros = np.full((sample_size, 9), 0)\n",
    "\n",
    "# all concatenated\n",
    "consonants = np.hstack((consonants, con_dur, zeros))\n",
    "\n",
    "print(consonants[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7bc116",
   "metadata": {},
   "source": [
    "### Vowel synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62d2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "vow_means = np.array([80, 200, 170, 110 ,90]) # voc_int, f0, b3, b2, b1\n",
    "vow_means = np.append(vow_means, f_vals) # *, f3, f2, f1\n",
    "vow_stds = vow_means * 0.05\n",
    "\n",
    "vowels = np.zeros((sample_size, len(vow_means)))\n",
    "for i in range(len(vow_means)):\n",
    "    a, b = (vow_means[i] - 2*vow_stds[i] - vow_means[i]) / vow_stds[i], (vow_means[i] + 2*vow_stds[i] - vow_means[i]) / vow_stds[i]\n",
    "    dist = truncnorm(a, b, loc = vow_means[i], scale = vow_stds[i])\n",
    "    vowels[:, i] = dist.rvs(size = sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422e3dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.            0.            0.            0.            0.\n",
      "    0.            0.          400.          400.           72.61917825\n",
      "  212.39485422  161.94203674  109.72841264   87.74978366 3172.51458626\n",
      " 2777.76843001  393.94701612]\n"
     ]
    }
   ],
   "source": [
    "# vocalic duration and total duration of fixed value 400 for vowels\n",
    "vow_dur = np.full((sample_size, 2), 400)\n",
    "\n",
    "# zero values for all other features\n",
    "zeros = np.full((sample_size, 7), 0)\n",
    "\n",
    "# all concatenated\n",
    "vowels = np.hstack((zeros, vow_dur, vowels))\n",
    "\n",
    "print(vowels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e26edb",
   "metadata": {},
   "source": [
    "### A csv file as guideline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b857a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shuhaoz19/Desktop/Workspace/2025_Allophone/gradient/data/structure_sample.csv\n"
     ]
    }
   ],
   "source": [
    "element = [\n",
    "    'cog', 'fri_dur', 'sta_dev', 'skewness', 'kurtosis', 'bur_int', 'fri_int', \n",
    "    'tot_dur', 'voc_dur', 'voc_int',\n",
    "    'f0', 'b3', 'b2', 'b1', 'f3', 'f2', 'f1'\n",
    "]\n",
    "\n",
    "explanation = [\n",
    "    'center of gravity', 'frication duration', 'standard deviation', 'skewness', 'kurtosis', 'burst intensity', 'frication intensity',\n",
    "    'total duration', 'vocalic duration', 'vocalic intensity',\n",
    "    'fundamental frequency', 'bandwidth of f3', 'bandwidth of f2', 'bandwidth of f1', 'f3', 'f2', 'f1'\n",
    "]\n",
    "\n",
    "mean = [\n",
    "    '4000, 7000', '96, 174', '200', '0.5', '1', '50', '60',\n",
    "    '200 for con, 400 for vow', '0 for con, 400 for vow', '0 for con, 80 for vow',\n",
    "    '200', '170', '110', '90', '', '', '']\n",
    "\n",
    "\n",
    "random = ['gaussian'] * 7 + ['fixed'] * 2 + ['gaussian'] * 8\n",
    "\n",
    "structure = pd.DataFrame({\n",
    "    'element': element,\n",
    "    'explanation': explanation, \n",
    "    'mean': mean,\n",
    "    'random': random,\n",
    "    'consonant_sample': consonants[0],\n",
    "    'consonant': consonant,\n",
    "    'vowel_sample': vowels[0],\n",
    "    'vowel': vowel\n",
    "})\n",
    "\n",
    "file_name = os.path.join(data_dir, 'structure_sample.csv')\n",
    "print(file_name)\n",
    "structure.to_csv(file_name, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167a6e7",
   "metadata": {},
   "source": [
    "### Save as 3*17 .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "150c7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "\n",
    "subdata_dir = os.path.join(data_dir, word)\n",
    "os.makedirs(subdata_dir, exist_ok=True)\n",
    "\n",
    "for i in range(sample_size):\n",
    "    uid = word + f'_{i+1:04d}'\n",
    "    filename = f'{uid}.npy'\n",
    "    save_path = os.path.join(subdata_dir, filename)\n",
    "    \n",
    "    vcv = np.vstack([vowels[i], consonants[i], vowels[i]])\n",
    "\n",
    "    np.save(save_path, vcv)\n",
    "    \n",
    "    cog = vcv[1][0]\n",
    "    fri_dur = vcv[1][1]\n",
    "    \n",
    "    save_path_rel = os.path.relpath(save_path, start=work_dir)\n",
    "\n",
    "    metadata.append({\n",
    "        'uid': uid,\n",
    "        'path': save_path_rel,\n",
    "        'cog': cog,\n",
    "        'fri_dur': fri_dur,\n",
    "        'word': word\n",
    "    })\n",
    "\n",
    "metaframe = pd.DataFrame(metadata)\n",
    "\n",
    "csv_name = word + '_meta.csv'\n",
    "csv_path = os.path.join(data_dir, csv_name)\n",
    "metaframe.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27812dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.00000000e+02\n",
      "  4.00000000e+02 7.62651996e+01 1.96561572e+02 1.63102878e+02\n",
      "  1.15253069e+02 8.59183158e+01 3.32123695e+03 2.83428375e+03\n",
      "  4.17138881e+02]\n",
      " [6.53557829e+03 1.77942891e+02 1.92521676e+02 5.02965259e-01\n",
      "  1.00111816e+00 4.57867281e+01 6.17065703e+01 2.00000000e+02\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.00000000e+02\n",
      "  4.00000000e+02 7.62651996e+01 1.96561572e+02 1.63102878e+02\n",
      "  1.15253069e+02 8.59183158e+01 3.32123695e+03 2.83428375e+03\n",
      "  4.17138881e+02]]\n"
     ]
    }
   ],
   "source": [
    "savetest = np.load(save_path)\n",
    "\n",
    "print(savetest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shuhao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
